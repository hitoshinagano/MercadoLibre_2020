{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - DATAPREP - Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dir setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "this_file_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# if script (not notebook)...\n",
    "# project_dir = os.path.join(os.path.dirname(__file__), os.pardir)\n",
    "\n",
    "# project directory\n",
    "project_dir = os.path.join(this_file_path, os.pardir)\n",
    "\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = os.path.join(project_dir, os.environ.get(\"RAW_DATA_DIR\"))\n",
    "processed_data_dir = os.path.join(project_dir, os.environ.get(\"PROCESSED_DATA_DIR\"))\n",
    "interim_data_dir = os.path.join(project_dir, os.environ.get(\"INTERIM_DATA_DIR\"))\n",
    "wordvecs_data_dir = os.path.join(project_dir, os.environ.get(\"WORDVECS_DATA_DIR\"))\n",
    "figures_dir = os.path.join(project_dir, os.environ.get(\"FIGURES_DIR\"))\n",
    "reports_dir = os.path.join(project_dir, os.environ.get(\"REPORTS_DIR\"))\n",
    "cv_dir = os.path.join(project_dir, os.environ.get(\"CV_DIR\"))\n",
    "models_dir = os.path.join(project_dir, os.environ.get(\"MODELS_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_OFFSET = int(os.environ.get(\"TEST_OFFSET\"))\n",
    "TOTAL_TEST_SEQS = int(os.environ.get(\"TOTAL_TEST_SEQS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_rows', 100)\n",
    "# pd.set_option('max_columns', None)\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hitoshinagano/.virtualenvs/tensorflow2/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# import mlflow\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "port_nlp_fn = 'nilc50skip'\n",
    "port_nlp_fp = os.path.join(wordvecs_data_dir, port_nlp_fn) \n",
    "port_nlp = spacy.load(port_nlp_fp)\n",
    "\n",
    "espa_nlp_fn = 'suc30fast'\n",
    "espa_nlp_fp = os.path.join(wordvecs_data_dir, espa_nlp_fn) \n",
    "espa_nlp = spacy.load(espa_nlp_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## project imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import *\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train/test search data dataprep for search info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang both\n"
     ]
    }
   ],
   "source": [
    "test_offset, test_shifted_seq_vals, train_test = join_prepare_train_test('train_dataset.pkl', \n",
    "                                                                         'test_dataset.pkl', \n",
    "                                                                         buy_weight = -1, \n",
    "                                                                         return_search = True, \n",
    "                                                                         drop_timezone = True,\n",
    "                                                                         drop_lang = False,\n",
    "                                                                         lang = 'both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### identifying language for each seq\n",
    "based on the browsed items and their domain MLB or MLM. <br>\n",
    "this part was moved inside join_prepare_train_test via arg lang (drop_lang must be False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### item_data\n",
    "\n",
    "# item_data_fn = 'item_data.pkl'\n",
    "# item_data_fp = os.path.join(processed_data_dir, item_data_fn)\n",
    "# item_data = pd.read_pickle(item_data_fp)\n",
    "# item_data = item_data_desc[['item_id', 'title', 'domain_id']]\n",
    "\n",
    "# lang = train_test[train_test.event_type == 'view'].copy()\n",
    "# lang['event_info'] = lang.event_info.astype(int)\n",
    "# lang = lang[['seq', 'event_info']]\n",
    "# lang = pd.merge(lang, item_data[['item_id', 'lang_domain']], how = 'left', \n",
    "#                  left_on = 'event_info', right_on = 'item_id')\n",
    "# lang = lang.groupby('seq').lang_domain.value_counts()\n",
    "# lang = lang.unstack().fillna(0).idxmax(axis = 1)\n",
    "# lang = lang.reset_index().rename(columns = {0: 'lang_seq'})\n",
    "\n",
    "# train_test = pd.merge(train_test, lang, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>event_info</th>\n",
       "      <th>views</th>\n",
       "      <th>event_type</th>\n",
       "      <th>lang_seq</th>\n",
       "      <th>in_nav</th>\n",
       "      <th>in_nav_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.61599e+06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>view</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.78615e+06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>view</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924622</th>\n",
       "      <td>0</td>\n",
       "      <td>RELOGIO SMARTWATCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>search</td>\n",
       "      <td>pt</td>\n",
       "      <td>False</td>\n",
       "      <td>0.655061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924639</th>\n",
       "      <td>0</td>\n",
       "      <td>1.74883e+06</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>buy</td>\n",
       "      <td>pt</td>\n",
       "      <td>False</td>\n",
       "      <td>0.655061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>206667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>view</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603664</th>\n",
       "      <td>590232</td>\n",
       "      <td>NUTELLA 650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>search</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603666</th>\n",
       "      <td>590232</td>\n",
       "      <td>NUTELLA 650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>search</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603668</th>\n",
       "      <td>590232</td>\n",
       "      <td>NUTELLA 650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>search</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603669</th>\n",
       "      <td>590232</td>\n",
       "      <td>XIAOMI MI 9 128GB PRETO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>search</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603670</th>\n",
       "      <td>590232</td>\n",
       "      <td>XIAOMI MI 9 128GB PRETO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>search</td>\n",
       "      <td>pt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13915241 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            seq               event_info  views event_type lang_seq in_nav  \\\n",
       "0             0              1.61599e+06   16.0       view      NaN    NaN   \n",
       "1             0              1.78615e+06    2.0       view      NaN    NaN   \n",
       "1924622       0       RELOGIO SMARTWATCH    NaN     search       pt  False   \n",
       "1924639       0              1.74883e+06   -1.0        buy       pt  False   \n",
       "2             1                   206667    1.0       view      NaN    NaN   \n",
       "...         ...                      ...    ...        ...      ...    ...   \n",
       "4603664  590232              NUTELLA 650    NaN     search       pt    NaN   \n",
       "4603666  590232              NUTELLA 650    NaN     search       pt    NaN   \n",
       "4603668  590232              NUTELLA 650    NaN     search       pt    NaN   \n",
       "4603669  590232  XIAOMI MI 9 128GB PRETO    NaN     search       pt    NaN   \n",
       "4603670  590232  XIAOMI MI 9 128GB PRETO    NaN     search       pt    NaN   \n",
       "\n",
       "         in_nav_pred  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "1924622     0.655061  \n",
       "1924639     0.655061  \n",
       "2                NaN  \n",
       "...              ...  \n",
       "4603664          NaN  \n",
       "4603666          NaN  \n",
       "4603668          NaN  \n",
       "4603669          NaN  \n",
       "4603670          NaN  \n",
       "\n",
       "[13915241 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### few seq's with no views. imputing with 'pt' (could run langdetect)\n",
    "approximately 6.4% of the seq's do not have views. check with <br>\n",
    "`train_test.groupby('seq').event_type.value_counts().unstack()['view'].isnull().value_counts(normalize = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.loc[train_test.lang_seq.isnull(), 'lang_seq'] = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embeddings for searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = train_test[train_test.event_type == 'search'].drop_duplicates(\n",
    "    subset = ['event_info', 'lang_seq'])\n",
    "searches = searches[['seq', 'event_info', 'lang_seq']]\n",
    "searches['query_lower'] = searches.event_info.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_vectors(x):\n",
    "    if x.lang_seq == 'pt':\n",
    "        v = port_nlp(x.query_lower) \n",
    "    else:\n",
    "        v = espa_nlp(x.query_lower)\n",
    "        \n",
    "    v_vector = v.vector\n",
    "    vector_norm = v.vector_norm\n",
    "    if vector_norm == 0:\n",
    "        return np.zeros(v_vector.shape, dtype = np.float16)\n",
    "    else:\n",
    "        return (v_vector / vector_norm).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1172171/1172171 [02:07<00:00, 9195.53it/s] \n"
     ]
    }
   ],
   "source": [
    "searches['query_embs'] = searches[['query_lower', 'lang_seq']].progress_apply(emb_vectors, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_info</th>\n",
       "      <th>lang_seq</th>\n",
       "      <th>query_embs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12126128</th>\n",
       "      <td>NS CONJUNTO</td>\n",
       "      <td>pt</td>\n",
       "      <td>[0.11017, -0.0712, 0.1914, -0.08746, -0.1422, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991506</th>\n",
       "      <td>PO TRANSPARENTE UNHA PORCELANA</td>\n",
       "      <td>pt</td>\n",
       "      <td>[-0.1888, -0.03647, 0.08826, -0.1487, 0.1819, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547447</th>\n",
       "      <td>PATINS ROLLER 4 FOR YOU NUMERO 34</td>\n",
       "      <td>pt</td>\n",
       "      <td>[0.1766, 0.0355, 0.1692, -0.1627, -0.05573, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828423</th>\n",
       "      <td>DISTINTIVO POLICIA CIVIL MT</td>\n",
       "      <td>pt</td>\n",
       "      <td>[-0.11237, -0.02359, -0.1588, -0.1804, -0.2908...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934363</th>\n",
       "      <td>CFW500 38A</td>\n",
       "      <td>pt</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159159</th>\n",
       "      <td>SUPORTES PRENDER JANELAS</td>\n",
       "      <td>pt</td>\n",
       "      <td>[0.012764, -0.001668, 0.0832, -0.01209, 0.0247...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975586</th>\n",
       "      <td>NUMARK TT 250 USB</td>\n",
       "      <td>pt</td>\n",
       "      <td>[0.0489, -0.1137, 0.2847, -0.0929, -0.0638, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033279</th>\n",
       "      <td>JOGO PARAFUSO TOYOTA COROLLA</td>\n",
       "      <td>pt</td>\n",
       "      <td>[0.1178, -0.0864, 0.2573, -0.1937, -0.1727, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227375</th>\n",
       "      <td>MESA GUITARRA</td>\n",
       "      <td>es</td>\n",
       "      <td>[-0.1285, 0.1699, -0.09875, 0.0996, 0.1921, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000707</th>\n",
       "      <td>DESS PUNTO</td>\n",
       "      <td>es</td>\n",
       "      <td>[0.03647, 0.02017, 0.1942, 0.1488, -0.001874, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 event_info lang_seq  \\\n",
       "12126128                        NS CONJUNTO       pt   \n",
       "3991506      PO TRANSPARENTE UNHA PORCELANA       pt   \n",
       "3547447   PATINS ROLLER 4 FOR YOU NUMERO 34       pt   \n",
       "3828423         DISTINTIVO POLICIA CIVIL MT       pt   \n",
       "3934363                          CFW500 38A       pt   \n",
       "1159159            SUPORTES PRENDER JANELAS       pt   \n",
       "7975586                   NUMARK TT 250 USB       pt   \n",
       "5033279        JOGO PARAFUSO TOYOTA COROLLA       pt   \n",
       "1227375                       MESA GUITARRA       es   \n",
       "1000707                          DESS PUNTO       es   \n",
       "\n",
       "                                                 query_embs  \n",
       "12126128  [0.11017, -0.0712, 0.1914, -0.08746, -0.1422, ...  \n",
       "3991506   [-0.1888, -0.03647, 0.08826, -0.1487, 0.1819, ...  \n",
       "3547447   [0.1766, 0.0355, 0.1692, -0.1627, -0.05573, -0...  \n",
       "3828423   [-0.11237, -0.02359, -0.1588, -0.1804, -0.2908...  \n",
       "3934363   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1159159   [0.012764, -0.001668, 0.0832, -0.01209, 0.0247...  \n",
       "7975586   [0.0489, -0.1137, 0.2847, -0.0929, -0.0638, -0...  \n",
       "5033279   [0.1178, -0.0864, 0.2573, -0.1937, -0.1727, 0....  \n",
       "1227375   [-0.1285, 0.1699, -0.09875, 0.0996, 0.1921, -0...  \n",
       "1000707   [0.03647, 0.02017, 0.1942, 0.1488, -0.001874, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches[['event_info', 'lang_seq', 'query_embs']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.merge(train_test, searches[['event_info', 'lang_seq', 'query_embs']], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving augmented train_test with search embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_embs_fn = 'train_test_embs.pkl'\n",
    "train_test_embs_fp = os.path.join(interim_data_dir, train_test_embs_fn)\n",
    "train_test.to_pickle(train_test_embs_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👆 search dataprep above. finishes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
