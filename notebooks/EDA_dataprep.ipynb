{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dir setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "this_file_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# if script (not notebook)...\n",
    "# project_dir = os.path.join(os.path.dirname(__file__), os.pardir)\n",
    "\n",
    "# project directory\n",
    "project_dir = os.path.join(this_file_path, os.pardir)\n",
    "\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = os.path.join(project_dir, os.environ.get(\"RAW_DATA_DIR\"))\n",
    "processed_data_dir = os.path.join(project_dir, os.environ.get(\"PROCESSED_DATA_DIR\"))\n",
    "interim_data_dir = os.path.join(project_dir, os.environ.get(\"INTERIM_DATA_DIR\"))\n",
    "wordvecs_data_dir = os.path.join(project_dir, os.environ.get(\"WORDVECS_DATA_DIR\"))\n",
    "figures_dir = os.path.join(project_dir, os.environ.get(\"FIGURES_DIR\"))\n",
    "reports_dir = os.path.join(project_dir, os.environ.get(\"REPORTS_DIR\"))\n",
    "cv_dir = os.path.join(project_dir, os.environ.get(\"CV_DIR\"))\n",
    "models_dir = os.path.join(project_dir, os.environ.get(\"MODELS_DIR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# import sweetviz as sv\n",
    "# import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hitoshinagano/.virtualenvs/tensorflow2/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "port_nlp_fn = 'nilc50skip'\n",
    "port_nlp_fp = os.path.join(wordvecs_data_dir, port_nlp_fn) \n",
    "port_nlp = spacy.load(port_nlp_fp)\n",
    "\n",
    "espa_nlp_fn = 'suc30fast'\n",
    "espa_nlp_fp = os.path.join(wordvecs_data_dir, espa_nlp_fn) \n",
    "espa_nlp = spacy.load(espa_nlp_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_data.jl.gz\n",
    "Note there are titles with the same texts, but with different item_id's.<br>\n",
    "check with `item_data[item_data.duplicated(subset = ['title'], keep = False)].sort_values('title')`\n",
    "\n",
    "Run this to reprocess a new `item_data.pkl` in `processed_data_dir`, for example with new embeddings (more dimensions on pre-trained, or custom embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data_fn = 'item_data.jl.gz'\n",
    "item_data = pd.read_json(os.path.join(raw_data_dir, item_data_fn), lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item_domain used in the scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_domain = item_domain[['item_id', 'domain_id']]\n",
    "item_domain_fn = 'item_domain.pkl'\n",
    "item_domain_fp = os.path.join(processed_data_dir, item_domain_fn)\n",
    "item_domain.to_pickle(item_domain_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLB: Brasil\n",
    "* MLM: Other countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLB    1723216\n",
       "MLM     378210\n",
       "Name: domain_id, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.domain_id.str[:3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data['title_lower'] = item_data.title.str.lower()\n",
    "item_data['lang_domain'] = item_data.domain_id.str[:3].replace({'MLM': 'es', 'MLB': 'pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data_unique = item_data[['title_lower', 'lang_domain']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_vectors(x):\n",
    "    if x.lang_domain == 'pt':\n",
    "        v = port_nlp(x.title_lower) \n",
    "    else:\n",
    "        v = espa_nlp(x.title_lower)\n",
    "        \n",
    "    v_vector = v.vector\n",
    "    vector_norm = v.vector_norm\n",
    "    if vector_norm == 0:\n",
    "        return np.zeros(v_vector.shape, dtype = np.float16)\n",
    "    else:\n",
    "        return (v_vector / vector_norm).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1925800/1925800 [05:17<00:00, 6071.83it/s]\n"
     ]
    }
   ],
   "source": [
    "item_data_unique['title_embs'] = item_data_unique.progress_apply(emb_vectors, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = pd.merge(item_data, item_data_unique, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data_fn = 'item_data.pkl'\n",
    "item_data_fp = os.path.join(processed_data_dir, item_data_fn)\n",
    "item_data.to_pickle(item_data_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = item_data[['item_id', 'lang_domain', 'title_embs']]\n",
    "\n",
    "item_data_embs_only_fn = 'item_data_embs_only.pkl'\n",
    "item_data_embs_only_fp = os.path.join(processed_data_dir, item_data_embs_only_fn)\n",
    "item_data.to_pickle(item_data_embs_only_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maybe cluster some of these domains into larger domains (smaller ones)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain_id\n",
       "MLM-GAME_CONSOLE_CAMERA_MOUNTS         1\n",
       "MLM-GOAL_NETS                          1\n",
       "MLM-GOLF_BAGS                          1\n",
       "MLM-GOLF_CLUBS_PUTTERS                 1\n",
       "MLM-GONIOMETERS                        1\n",
       "MLM-GPS_CASES_AND_COVERS               1\n",
       "MLM-GRADUATED_CYLINDERS                1\n",
       "MLM-GRANOLA                            1\n",
       "MLM-GRASS_PAVERS                       1\n",
       "MLM-GROOMING_TABLES                    1\n",
       "MLM-GROUND_RESISTANCE_METERS           1\n",
       "MLM-STACKABLE_BINS                     1\n",
       "MLM-HABERDASHERY_FABRIC_FLOWERS        1\n",
       "MLM-HABERDASHERY_FRINGES               1\n",
       "MLB-INDUSTRIAL_SILOS                   1\n",
       "MLM-ALL_TERRAIN_VEHICLE_DRIVE_BELTS    1\n",
       "MLM-STOLES                             1\n",
       "MLM-GLASS_SAFETY_FILMS                 1\n",
       "MLM-AUTOMOTIVE_TRASH_BAGS              1\n",
       "MLM-ALARM_REMOTE_CONTROLS              1\n",
       "Name: item_id, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.groupby('domain_id').item_id.count().sort_values().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain_id\n",
       "MLB-MOTORCYCLES                            10155\n",
       "MLB-INDUSTRIAL_AND_COMMERCIAL_EQUIPMENT    10252\n",
       "MLB-PANTS                                  10309\n",
       "MLB-SOUVENIRS                              11017\n",
       "MLB-CELLPHONE_COVERS                       11177\n",
       "MLB-HEADPHONES                             11328\n",
       "MLB-VIDEO_GAMES                            12742\n",
       "MLB-WRISTWATCHES                           13136\n",
       "MLB-HAIR_TREATMENTS                        13529\n",
       "MLB-ACTION_FIGURES                         13597\n",
       "MLM-CARS_AND_VANS                          14165\n",
       "MLB-SANDALS_AND_FLIP_FLOPS                 15102\n",
       "MLB-VEHICLE_PARTS                          18727\n",
       "MLB-DRESSES                                21590\n",
       "MLB-SUPPLEMENTS                            22351\n",
       "MLB-T_SHIRTS                               23823\n",
       "MLB-VEHICLE_ACCESSORIES                    28986\n",
       "MLB-SNEAKERS                               32636\n",
       "MLB-CELLPHONES                             38390\n",
       "MLB-CARS_AND_VANS                          41420\n",
       "Name: item_id, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data.groupby('domain_id').item_id.count().sort_values().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_dataset.jl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_dataset(df):\n",
    "    number_of_batches = len(df) // 50\n",
    "    proc_df = list()\n",
    "    for df_p in tqdm(np.array_split(df, number_of_batches)):\n",
    "        if 'item_bought' in df_p:\n",
    "            df_p = pd.concat([df_p.user_history.apply(pd.Series), df_p.item_bought], axis = 1).stack()\n",
    "            train_dataset = True\n",
    "        else:\n",
    "            df_p = df_p.user_history.apply(pd.Series).stack()\n",
    "            train_dataset = False\n",
    "            \n",
    "        df_p = df_p.apply(pd.Series)\n",
    "        df_p.reset_index(inplace = True)\n",
    "        df_p.drop(columns = 'level_1', inplace = True)\n",
    "        \n",
    "        if train_dataset:\n",
    "            new_columns = {0: 'item_bought', 'level_0': 'seq'}\n",
    "            df_p['event_type'] = df_p.event_type.fillna('buy')\n",
    "        else:\n",
    "            new_columns = {'level_0': 'seq'}\n",
    "        \n",
    "        df_p.rename(columns = new_columns, inplace = True)\n",
    "        \n",
    "        # df_p['timezone'] = df_p.event_timestamp.str[-4:]\n",
    "        df_p['event_timestamp'] = pd.to_datetime(df_p.event_timestamp.str[:-9])\n",
    "        df_p['time_diff'] = df_p.groupby('seq').event_timestamp.diff().dt.seconds\n",
    "        \n",
    "        # if train_dataset:\n",
    "        proc_df.append(df_p)\n",
    "        \n",
    "    proc_df = pd.concat(proc_df)        \n",
    "    return proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(raw_fn = 'train_dataset.jl.gz', processed_fn = 'train_dataset.pkl',\n",
    "              force_process = False, nrows = None):\n",
    "\n",
    "    processed_fp = os.path.join(processed_data_dir, processed_fn)\n",
    "    if os.path.exists(processed_fp) and not force_process:\n",
    "        processed = pd.read_pickle(processed_fp)\n",
    "    else:\n",
    "        raw = pd.read_json(os.path.join(raw_data_dir, raw_fn), lines = True, nrows = nrows)\n",
    "        raw['len_events'] = raw.user_history.str.len()\n",
    "        raw.sort_values('len_events', inplace = True)\n",
    "        raw.drop('len_events', axis = 1, inplace = True)\n",
    "        processed = proc_dataset(raw)\n",
    "        processed.to_pickle(os.path.join(processed_data_dir, processed_fn))\n",
    "        \n",
    "    if 'item_bought' in processed: \n",
    "        processed.item_bought = processed.item_bought.fillna(method = 'backfill').astype(int)\n",
    "        processed['in_nav'] = processed.item_bought == processed.event_info\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.43 s, sys: 893 ms, total: 5.32 s\n",
      "Wall time: 5.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = read_data('train_dataset.jl.gz', 'train_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_true_labels(df, true_fn = 'true.pkl'):\n",
    "    true_fp = os.path.join(processed_data_dir, true_fn)\n",
    "    true_df = df[(df.event_type.isnull()) | (df.event_type == 'buy')]\n",
    "    true_df = true_df[['seq', 'item_bought']]\n",
    "    true_df.to_pickle(true_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_true_labels(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4% of the events correspond to the item bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.959279\n",
       "True     0.040721\n",
       "Name: in_nav, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.in_nav.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30% of the items bought show up in the navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.706116\n",
       "True     0.293884\n",
       "Name: in_nav, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('seq').in_nav.any().value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>item_bought</th>\n",
       "      <th>event_info</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>event_type</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>in_nav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>MINOXIDIL</td>\n",
       "      <td>2019-10-13 15:33:41</td>\n",
       "      <td>search</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>MINOXIDIL</td>\n",
       "      <td>2019-10-13 17:08:36</td>\n",
       "      <td>search</td>\n",
       "      <td>5695.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>429456</td>\n",
       "      <td>2019-10-13 17:09:04</td>\n",
       "      <td>view</td>\n",
       "      <td>28.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>429456</td>\n",
       "      <td>2019-10-13 17:09:43</td>\n",
       "      <td>view</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>429456</td>\n",
       "      <td>2019-10-13 17:10:37</td>\n",
       "      <td>view</td>\n",
       "      <td>54.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>MINOXIDIL</td>\n",
       "      <td>2019-10-13 17:10:38</td>\n",
       "      <td>search</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>625179</td>\n",
       "      <td>2019-10-13 17:10:46</td>\n",
       "      <td>view</td>\n",
       "      <td>8.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>MINOXIDIL</td>\n",
       "      <td>2019-10-13 17:10:58</td>\n",
       "      <td>search</td>\n",
       "      <td>12.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>410942</td>\n",
       "      <td>2019-10-13 17:11:45</td>\n",
       "      <td>view</td>\n",
       "      <td>47.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>410942</td>\n",
       "      <td>2019-10-13 17:12:29</td>\n",
       "      <td>view</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>MINOXIDIL</td>\n",
       "      <td>2019-10-13 17:12:31</td>\n",
       "      <td>search</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>1282024</td>\n",
       "      <td>2019-10-13 17:12:41</td>\n",
       "      <td>view</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>MINOXIDIL</td>\n",
       "      <td>2019-10-13 17:12:51</td>\n",
       "      <td>search</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>388604</td>\n",
       "      <td>2019-10-13 17:13:08</td>\n",
       "      <td>view</td>\n",
       "      <td>17.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>388604</td>\n",
       "      <td>2019-10-13 17:13:56</td>\n",
       "      <td>view</td>\n",
       "      <td>48.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>388604</td>\n",
       "      <td>2019-10-13 17:15:01</td>\n",
       "      <td>view</td>\n",
       "      <td>65.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>MINOXIDIL</td>\n",
       "      <td>2019-10-13 17:15:02</td>\n",
       "      <td>search</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>429456</td>\n",
       "      <td>2019-10-13 17:15:04</td>\n",
       "      <td>view</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>429456</td>\n",
       "      <td>2019-10-13 17:15:18</td>\n",
       "      <td>view</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>WHEY PROTEIN</td>\n",
       "      <td>2019-10-13 17:15:28</td>\n",
       "      <td>search</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>514205</td>\n",
       "      <td>2019-10-13 17:16:26</td>\n",
       "      <td>view</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>514205</td>\n",
       "      <td>2019-10-13 17:17:42</td>\n",
       "      <td>view</td>\n",
       "      <td>76.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>514205</td>\n",
       "      <td>2019-10-13 17:17:49</td>\n",
       "      <td>view</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>121</td>\n",
       "      <td>388604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq  item_bought    event_info     event_timestamp event_type  time_diff  \\\n",
       "864  121       388604     MINOXIDIL 2019-10-13 15:33:41     search        NaN   \n",
       "865  121       388604     MINOXIDIL 2019-10-13 17:08:36     search     5695.0   \n",
       "866  121       388604        429456 2019-10-13 17:09:04       view       28.0   \n",
       "867  121       388604        429456 2019-10-13 17:09:43       view       39.0   \n",
       "868  121       388604        429456 2019-10-13 17:10:37       view       54.0   \n",
       "869  121       388604     MINOXIDIL 2019-10-13 17:10:38     search        1.0   \n",
       "870  121       388604        625179 2019-10-13 17:10:46       view        8.0   \n",
       "871  121       388604     MINOXIDIL 2019-10-13 17:10:58     search       12.0   \n",
       "872  121       388604        410942 2019-10-13 17:11:45       view       47.0   \n",
       "873  121       388604        410942 2019-10-13 17:12:29       view       44.0   \n",
       "874  121       388604     MINOXIDIL 2019-10-13 17:12:31     search        2.0   \n",
       "875  121       388604       1282024 2019-10-13 17:12:41       view       10.0   \n",
       "876  121       388604     MINOXIDIL 2019-10-13 17:12:51     search       10.0   \n",
       "877  121       388604        388604 2019-10-13 17:13:08       view       17.0   \n",
       "878  121       388604        388604 2019-10-13 17:13:56       view       48.0   \n",
       "879  121       388604        388604 2019-10-13 17:15:01       view       65.0   \n",
       "880  121       388604     MINOXIDIL 2019-10-13 17:15:02     search        1.0   \n",
       "881  121       388604        429456 2019-10-13 17:15:04       view        2.0   \n",
       "882  121       388604        429456 2019-10-13 17:15:18       view       14.0   \n",
       "883  121       388604  WHEY PROTEIN 2019-10-13 17:15:28     search       10.0   \n",
       "884  121       388604        514205 2019-10-13 17:16:26       view       58.0   \n",
       "885  121       388604        514205 2019-10-13 17:17:42       view       76.0   \n",
       "886  121       388604        514205 2019-10-13 17:17:49       view        7.0   \n",
       "887  121       388604           NaN                 NaT        NaN        NaN   \n",
       "\n",
       "     in_nav  \n",
       "864   False  \n",
       "865   False  \n",
       "866   False  \n",
       "867   False  \n",
       "868   False  \n",
       "869   False  \n",
       "870   False  \n",
       "871   False  \n",
       "872   False  \n",
       "873   False  \n",
       "874   False  \n",
       "875   False  \n",
       "876   False  \n",
       "877    True  \n",
       "878    True  \n",
       "879    True  \n",
       "880   False  \n",
       "881   False  \n",
       "882   False  \n",
       "883   False  \n",
       "884   False  \n",
       "885   False  \n",
       "886   False  \n",
       "887   False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query(\"seq == 121\")#.time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 49% of the domain_id of items bought show up in the navigated domain_id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, item_data[['item_id', 'domain_id']], how = 'left', \n",
    "                 left_on = 'item_bought', right_on = 'item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns = {'domain_id': 'bought_domain_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, item_data[['item_id', 'domain_id']], how = 'left', \n",
    "                 left_on = 'event_info', right_on = 'item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns = {'domain_id': 'nav_domain_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['item_id_x', 'item_id_y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['in_nav_domain'] = train.bought_domain_id == train.nav_domain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.506594\n",
       "True     0.493406\n",
       "Name: in_nav_domain, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('seq').in_nav_domain.any().value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_dataset.jl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3541/3541 [34:21<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 41s, sys: 17.4 s, total: 34min 58s\n",
      "Wall time: 34min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = read_data('test_dataset.jl.gz', 'test_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test_dataset.jl.gz\n",
    "* sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
